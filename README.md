# GPU Lab Monitor

ç ”ç©¶å®¤ã®GPUã‚µãƒ¼ãƒãƒ¼ç¾¤ã‚’ä¸€å…ƒç®¡ç†ã™ã‚‹ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã™ã€‚
å„ã‚µãƒ¼ãƒãƒ¼ã®GPUä½¿ç”¨ç‡ã€æ¸©åº¦ã€é›»åŠ›ã€ãã—ã¦**ç¾åœ¨èª°ãŒï¼ˆã©ã®Dockerã‚³ãƒ³ãƒ†ãƒŠãŒï¼‰GPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹**ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚

SSHãƒ­ã‚°ã‚¤ãƒ³ã‚„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã¯ä¸è¦ã€‚IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ç™»éŒ²ã™ã‚‹ã ã‘ã§ã€Webãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚¿å…¨ä½“ã®çŠ¶æ³ã‚’æŠŠæ¡ã§ãã¾ã™ã€‚

---

## ğŸ›  å‰ææ¡ä»¶

**ç®¡ç†è€…PC (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºç”¨)**
- Node.js (v16ä»¥ä¸Šæ¨å¥¨)
- Git

**ç›£è¦–å¯¾è±¡GPUã‚µãƒ¼ãƒãƒ¼ (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨)**
- Linux (Ubuntuç­‰)
- NVIDIA Driver & nvidia-smi
- Python 3.x
- Docker (ã‚³ãƒ³ãƒ†ãƒŠæƒ…å ±ã®å–å¾—ã«å¿…è¦)

---

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### Step 1: ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ (ç®¡ç†è€…PC)

ã¾ãšã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/your-username/gpu-lab-monitor.git

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd gpu-lab-monitor
```

---

### Step 2: ç›£è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰ (GPUã‚µãƒ¼ãƒãƒ¼å´)

**â€»ã“ã®ä½œæ¥­ã¯ã€ç›£è¦–ã—ãŸã„å…¨ã¦ã®GPUã‚µãƒ¼ãƒãƒ¼ã§è¡Œã£ã¦ãã ã•ã„ã€‚**

å„ã‚µãƒ¼ãƒãƒ¼ä¸Šã§ã€Œè‡ªåˆ†ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’JSONã§è¿”ã™ã€å°ã•ãªWebã‚µãƒ¼ãƒãƒ¼ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’ç«‹ã¡ä¸Šã’ã¾ã™ã€‚

#### 1. å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
sudo apt update
sudo apt install -y python3-pip
pip3 install fastapi uvicorn
```

#### 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
é©å½“ãªå ´æ‰€ï¼ˆä¾‹: `/opt/gpu-monitor`ï¼‰ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ `monitor.py` ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚

**ãƒ•ã‚¡ã‚¤ãƒ«: `/opt/gpu-monitor/monitor.py`**

```python
import subprocess
import csv
import io
import json
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# CORSè¨­å®š: ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_docker_map():
    """
    å®Ÿè¡Œä¸­ã®Dockerã‚³ãƒ³ãƒ†ãƒŠã®PIDã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹è¾æ›¸ã‚’ä½œæˆ
    Returns: {pid: {name: str, user: str, image: str}}
    """
    docker_map = {}
    try:
        # å®Ÿè¡Œä¸­ã®å…¨ã‚³ãƒ³ãƒ†ãƒŠã®PID, åå‰, Image, Config.Userã‚’å–å¾—
        cmd = ["docker", "ps", "-q"]
        container_ids = subprocess.check_output(cmd).decode().split()
        
        if not container_ids:
            return {}

        inspect_cmd = ["docker", "inspect", "--format", "{{.State.Pid}},{{.Name}},{{.Config.User}},{{.Config.Image}}"] + container_ids
        output = subprocess.check_output(inspect_cmd).decode()
        
        for line in output.splitlines():
            if not line.strip(): continue
            parts = line.split(',')
            if len(parts) >= 4:
                pid = int(parts[0])
                name = parts[1].strip().lstrip('/') # å…ˆé ­ã®/ã‚’é™¤å»
                user = parts[2].strip()
                image = parts[3].strip()
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç©ºãªã‚‰rootã¨ã™ã‚‹ã€ã¾ãŸã¯ã‚¤ãƒ¡ãƒ¼ã‚¸åãªã©ã‚’ãƒ’ãƒ³ãƒˆã«ã™ã‚‹
                if not user: user = "root"
                
                docker_map[pid] = {
                    "containerName": name,
                    "user": user,
                    "image": image
                }
    except Exception as e:
        print(f"Docker info fetch error: {e}")
    
    return docker_map

def get_gpu_processes():
    """
    nvidia-smiã‹ã‚‰ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—ã—ã€Dockeræƒ…å ±ã¨çµåˆã™ã‚‹
    """
    processes = []
    docker_map = get_docker_map()

    try:
        # PID, Process Name, Used Memory
        cmd = ["nvidia-smi", "--query-compute-apps=pid,process_name,used_memory", "--format=csv,noheader,nounits"]
        output = subprocess.check_output(cmd).decode()
        
        for line in output.splitlines():
            if not line.strip(): continue
            parts = line.split(',')
            pid = int(parts[0])
            proc_name = parts[1].strip()
            mem_used = int(parts[2])
            
            # Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã®ãƒ—ãƒ­ã‚»ã‚¹ã‹ãƒã‚§ãƒƒã‚¯
            # æ­£ç¢ºã«ã¯ãƒ—ãƒ­ã‚»ã‚¹ã®è¦ªPIDã‚’è¾¿ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ç°¡æ˜“çš„ã«PIDç›´æ¥ä¸€è‡´ã¾ãŸã¯cgroupç¢ºèªãŒä¸€èˆ¬çš„
            # ã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦PIDãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ (â€»å®Ÿéš›ã¯PID Namespaceã®é•ã„ã«ã‚ˆã‚Šãƒ›ã‚¹ãƒˆPIDã¨ç•°ãªã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚æ³¨æ„)
            # ã‚ˆã‚Šç¢ºå®Ÿã«ã™ã‚‹ã«ã¯ /proc/{pid}/cgroup ã‚’èª­ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒã€ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã—ã¦ã„ã¾ã™ã€‚
            
            # ãƒ›ã‚¹ãƒˆå´PIDã§è¦‹ã¤ã‹ã£ãŸå ´åˆ
            container_info = docker_map.get(pid)
            
            user = "system"
            container_name = None
            
            if container_info:
                user = container_info['user']
                container_name = container_info['containerName']
            
            processes.append({
                "pid": pid,
                "type": "C", # Compute
                "processName": proc_name,
                "usedMemory": mem_used,
                "user": user,
                "containerName": container_name
            })
            
    except Exception as e:
        # ãƒ—ãƒ­ã‚»ã‚¹ãŒãªã„å ´åˆãªã©
        pass
        
    return processes

@app.get("/metrics")
def metrics():
    # 1. GPUåŸºæœ¬æƒ…å ±ã®å–å¾—
    try:
        cmd = [
            "nvidia-smi",
            "--query-gpu=index,name,utilization.gpu,utilization.memory,memory.total,memory.used,memory.free,temperature.gpu,power.draw,power.limit",
            "--format=csv,noheader,nounits"
        ]
        res = subprocess.check_output(cmd).decode("utf-8")
        reader = csv.reader(io.StringIO(res))
        
        gpus = []
        all_processes = get_gpu_processes()

        for row in reader:
            index = int(row[0])
            
            # ã“ã®GPUã«é–¢é€£ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“å®Ÿè£…: æœ¬æ¥ã¯gpu_uuidç­‰ã§ç´ä»˜ã‘ãŒå¿…è¦ï¼‰
            # ã“ã“ã§ã¯å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¹ãƒˆã«å…¥ã‚Œã¦ã„ã¾ã™ãŒã€å®Ÿé‹ç”¨ã§ã¯ `nvidia-smi query-compute-apps` ã« `gpu_index` ã‚’å«ã‚ã¦ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦ãã ã•ã„
            
            gpus.append({
                "index": index,
                "name": row[1].strip(),
                "utilization": {
                    "gpu": int(row[2]),
                    "memory": int(row[3])
                },
                "memory": {
                    "total": int(row[4]),
                    "used": int(row[5]),
                    "free": int(row[6])
                },
                "temperature": int(row[7]),
                "power": {
                    "draw": float(row[8]),
                    "limit": float(row[9])
                },
                "processes": all_processes # â€»ç°¡ç•¥åŒ–ã®ãŸã‚å…¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¿”ã—ã¦ã„ã¾ã™
            })
            
        return {"status": "online", "gpus": gpus}
        
    except Exception as e:
        return {"status": "error", "message": str(e), "gpus": []}

if __name__ == "__main__":
    import uvicorn
    # ãƒãƒ¼ãƒˆ8000ã§å…¨IPã‹ã‚‰ã®æ¥ç¶šã‚’å¾…æ©Ÿ
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 3. è‡ªå‹•èµ·å‹•ã®è¨­å®š (Systemd)

ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•æ™‚ã«ã‚‚è‡ªå‹•çš„ã«ç›£è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç«‹ã¡ä¸ŠãŒã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```bash
# ã‚µãƒ¼ãƒ“ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
sudo nano /etc/systemd/system/gpu-monitor.service
```

ä»¥ä¸‹ã®å†…å®¹ã‚’è²¼ã‚Šä»˜ã‘ã¾ã™ï¼š

```ini
[Unit]
Description=GPU Monitoring API Agent
After=network.target docker.service

[Service]
User=root
WorkingDirectory=/opt/gpu-monitor
ExecStart=/usr/local/bin/uvicorn monitor:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

ä¿å­˜ã—ã¦ã‚¨ãƒ‡ã‚£ã‚¿ã‚’çµ‚äº†ã—ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚’æœ‰åŠ¹åŒ–ãƒ»èµ·å‹•ã—ã¾ã™ã€‚

```bash
sudo systemctl daemon-reload
sudo systemctl enable gpu-monitor
sudo systemctl start gpu-monitor
```

---

### Step 3: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ãƒ—ãƒªã®èµ·å‹• (ç®¡ç†è€…PC)

å†ã³ç®¡ç†è€…PCï¼ˆãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸPCï¼‰ã«æˆ»ã‚Šã¾ã™ã€‚

#### 1. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
npm install
```

#### 2. ãƒ¢ãƒ¼ãƒ‰ã®åˆ‡ã‚Šæ›¿ãˆï¼ˆé‡è¦ï¼‰
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚
**å®Ÿéš›ã®ã‚µãƒ¼ãƒãƒ¼ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚**

ãƒ•ã‚¡ã‚¤ãƒ«: `services/mockData.ts`

```typescript
// services/mockData.ts ã®æœ«å°¾ (115è¡Œç›®ä»˜è¿‘)

// å¤‰æ›´å‰:
export const fetchServerData = fetchMockServerData;
// export const fetchServerData = fetchRealServerData;

// å¤‰æ›´å¾Œï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å…¥ã‚Œæ›¿ãˆã‚‹ï¼‰:
// export const fetchServerData = fetchMockServerData;
export const fetchServerData = fetchRealServerData;
```

#### 3. ã‚¢ãƒ—ãƒªã®èµ·å‹•
é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚

```bash
npm start
```

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:3000`ï¼ˆã¾ãŸã¯è¡¨ç¤ºã•ã‚ŒãŸURLï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚
å³ä¸Šã®ã€ŒAdd Serverã€ãƒœã‚¿ãƒ³ã‹ã‚‰ã€Step 2ã§è¨­å®šã—ãŸã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆä¾‹: `192.168.1.50`ï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

---

### Step 4: Webã‚µãƒ¼ãƒãƒ¼ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

ã“ã®ã‚¢ãƒ—ãƒªã‚’æ°¸ç¶šçš„ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹æ–¹æ³•ã¯2ã¤ã‚ã‚Šã¾ã™ã€‚

#### A. ç ”ç©¶å®¤å†…ã®ã‚µãƒ¼ãƒãƒ¼ã§é…ä¿¡ã™ã‚‹ï¼ˆæ¨å¥¨ï¼‰
ç ”ç©¶å®¤å†…ã®Webã‚µãƒ¼ãƒãƒ¼ï¼ˆnginxã‚„Apacheï¼‰ã«ãƒ“ãƒ«ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¾ã™ã€‚
```bash
npm run build
# build/ ãƒ•ã‚©ãƒ«ãƒ€ã®ä¸­èº«ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ«ãƒ¼ãƒˆã¸ã‚³ãƒ”ãƒ¼
```
â€» åŒã˜LANå†…ã§ã‚ã‚Œã°HTTPåŒå£«ã§é€šä¿¡ã§ãã‚‹ãŸã‚ã€ãƒˆãƒ©ãƒ–ãƒ«ãŒå°‘ãªã„æœ€ã‚‚æ¨å¥¨ã•ã‚Œã‚‹æ–¹æ³•ã§ã™ã€‚

#### B. GitHub Pages ã§å…¬é–‹ã™ã‚‹
ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šï¼ˆ`username.github.io`ï¼‰ã‹ã‚‰ç ”ç©¶å®¤å†…ã®ã‚µãƒ¼ãƒãƒ¼ã‚’è¦‹ã«è¡Œãã¾ã™ã€‚
**HTTPSã¨HTTPã®æ··åœ¨ï¼ˆMixed Contentï¼‰å•é¡Œ**ã¸ã®å¯¾å‡¦ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚

ğŸ‘‰ **[è©³ç´°ãªæ‰‹é †ã¨è¨­å®šæ–¹æ³•ã¯ã“ã¡ã‚‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„](docs/GITHUB_PAGES.md)**
