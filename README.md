# GPU Lab Monitor

ç ”ç©¶å®¤ã®GPUã‚µãƒ¼ãƒãƒ¼ç¾¤ã‚’ä¸€å…ƒç®¡ç†ã™ã‚‹ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã™ã€‚
å„ã‚µãƒ¼ãƒãƒ¼ã®GPUä½¿ç”¨ç‡ã€æ¸©åº¦ã€é›»åŠ›ã€ãã—ã¦**ç¾åœ¨èª°ãŒï¼ˆã©ã®Dockerã‚³ãƒ³ãƒ†ãƒŠãŒï¼‰GPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹**ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚

SSHãƒ­ã‚°ã‚¤ãƒ³ã‚„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã¯ä¸è¦ã€‚IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ç™»éŒ²ã™ã‚‹ã ã‘ã§ã€Webãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚¿å…¨ä½“ã®çŠ¶æ³ã‚’æŠŠæ¡ã§ãã¾ã™ã€‚

---

## ğŸ›  å‰ææ¡ä»¶

**ç®¡ç†è€…PC (ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºç”¨)**
- Node.js (v16ä»¥ä¸Šæ¨å¥¨)
- Git

**ç›£è¦–å¯¾è±¡GPUã‚µãƒ¼ãƒãƒ¼ (ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨)**
- Linux (Ubuntuç­‰)
- NVIDIA Driver & nvidia-smi
- Python 3.x
- Docker (ã‚³ãƒ³ãƒ†ãƒŠæƒ…å ±ã®å–å¾—ã«å¿…è¦)

---

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### Step 1: ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ (ç®¡ç†è€…PC)

ã¾ãšã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/your-username/gpu-lab-monitor.git

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd gpu-lab-monitor
```

---

### Step 2: ç›£è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰ (GPUã‚µãƒ¼ãƒãƒ¼å´)

**â€»ã“ã®ä½œæ¥­ã¯ã€ç›£è¦–ã—ãŸã„å…¨ã¦ã®GPUã‚µãƒ¼ãƒãƒ¼ã§è¡Œã£ã¦ãã ã•ã„ã€‚**

å„ã‚µãƒ¼ãƒãƒ¼ä¸Šã§ã€Œè‡ªåˆ†ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’JSONã§è¿”ã™ã€å°ã•ãªWebã‚µãƒ¼ãƒãƒ¼ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’ç«‹ã¡ä¸Šã’ã¾ã™ã€‚

#### 1. å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
sudo apt update
sudo apt install -y python3-pip
pip3 install fastapi uvicorn
```

#### 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
ãƒªãƒã‚¸ãƒˆãƒªã«å«ã¾ã‚Œã¦ã„ã‚‹ `monitor.py` ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ä»¥ä¸‹ã®å†…å®¹ã§`/opt/gpu-monitor/monitor.py`ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ `nvidia-smi` ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ã€Dockerã‚³ãƒ³ãƒ†ãƒŠã¨ã®ç´ä»˜ã‘ã‚’è¡Œã„ã¾ã™ã€‚

**ãƒ•ã‚¡ã‚¤ãƒ«: `monitor.py`**

```python
import subprocess
import csv
import io
import json
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# CORSè¨­å®š: ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

def safe_int(val):
    """'40 MiB', '[N/A]', 'Error' ãªã©ã‚’å®‰å…¨ã«intã«å¤‰æ›"""
    try:
        # "40 MiB" -> "40"
        cleaned = str(val).split()[0].strip()
        return int(float(cleaned))
    except:
        return 0

def safe_float(val):
    """'45.5 W' ãªã©ã‚’å®‰å…¨ã«floatã«å¤‰æ›"""
    try:
        cleaned = str(val).split()[0].strip()
        return float(cleaned)
    except:
        return 0.0

def get_docker_map():
    """å®Ÿè¡Œä¸­ã®Dockerã‚³ãƒ³ãƒ†ãƒŠã®PIDã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°"""
    docker_map = {}
    try:
        cmd = ["docker", "ps", "-q"]
        container_ids = subprocess.check_output(cmd).decode().split()
        if not container_ids: return {}

        inspect_cmd = ["docker", "inspect", "--format", "{{.State.Pid}},{{.Name}},{{.Config.User}},{{.Config.Image}}"] + container_ids
        output = subprocess.check_output(inspect_cmd).decode()
        
        for line in output.splitlines():
            if not line.strip(): continue
            parts = line.split(',')
            if len(parts) >= 4:
                pid = safe_int(parts[0])
                name = parts[1].strip().lstrip('/')
                user = parts[2].strip() or "root"
                image = parts[3].strip()
                docker_map[pid] = {"containerName": name, "user": user, "image": image}
    except Exception as e:
        print(f"Docker info fetch error: {e}")
    return docker_map

def get_gpu_processes():
    """nvidia-smiã‹ã‚‰ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±ã‚’å–å¾—ã—ã€Dockeræƒ…å ±ã¨çµåˆ"""
    processes = []
    docker_map = get_docker_map()

    try:
        # gpu_index, pid, process_name, used_memory
        cmd = ["nvidia-smi", "--query-compute-apps=gpu_index,pid,process_name,used_memory", "--format=csv,noheader,nounits"]
        output = subprocess.check_output(cmd).decode()
        reader = csv.reader(io.StringIO(output))
        
        for row in reader:
            if len(row) < 4: continue
            
            gpu_idx = safe_int(row[0])
            pid = safe_int(row[1])
            proc_name = row[2].strip()
            mem_used = safe_int(row[3])
            
            container_info = docker_map.get(pid)
            user = container_info['user'] if container_info else "system"
            container_name = container_info['containerName'] if container_info else None
            
            processes.append({
                "gpuIndex": gpu_idx,
                "pid": pid,
                "type": "C",
                "processName": proc_name,
                "usedMemory": mem_used,
                "user": user,
                "containerName": container_name
            })
    except Exception:
        pass # ãƒ—ãƒ­ã‚»ã‚¹ãŒãªã„å ´åˆ
    return processes

@app.get("/")
def root():
    return {"message": "GPU Monitor Agent is Running. Access /metrics for data."}

@app.get("/metrics")
def metrics():
    try:
        cmd = [
            "nvidia-smi",
            "--query-gpu=index,name,utilization.gpu,utilization.memory,memory.total,memory.used,memory.free,temperature.gpu,power.draw,power.limit",
            "--format=csv,noheader,nounits"
        ]
        res = subprocess.check_output(cmd).decode("utf-8")
        reader = csv.reader(io.StringIO(res))
        
        gpus = []
        all_processes = get_gpu_processes()

        for row in reader:
            if len(row) < 10: continue
            
            # å®‰å…¨ã«ãƒ‘ãƒ¼ã‚¹
            index = safe_int(row[0])
            name = row[1].strip()
            util_gpu = safe_int(row[2])
            util_mem = safe_int(row[3])
            mem_total = safe_int(row[4])
            mem_used = safe_int(row[5])
            mem_free = safe_int(row[6])
            temp = safe_int(row[7])
            power_draw = safe_int(row[8]) # Wattã¯æ•´æ•°è¡¨ç¤ºã§ååˆ†
            power_limit = safe_int(row[9])
            
            # ã“ã®GPUã«é–¢é€£ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            gpu_processes = [p for p in all_processes if p['gpuIndex'] == index]

            gpus.append({
                "index": index,
                "name": name,
                "utilization": {"gpu": util_gpu, "memory": util_mem},
                "memory": {"total": mem_total, "used": mem_used, "free": mem_free},
                "temperature": temp,
                "power": {"draw": power_draw, "limit": power_limit},
                "processes": gpu_processes
            })
            
        return {"status": "online", "gpus": gpus}
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚JSONã‚’è¿”ã—ã¦ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        return {"status": "error", "message": str(e), "gpus": []}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

#### 3. è‡ªå‹•èµ·å‹•ã®è¨­å®š (Systemd)

ã‚µãƒ¼ãƒãƒ¼å†èµ·å‹•æ™‚ã«ã‚‚è‡ªå‹•çš„ã«ç›£è¦–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç«‹ã¡ä¸ŠãŒã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

```bash
# ã‚µãƒ¼ãƒ“ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
sudo nano /etc/systemd/system/gpu-monitor.service
```

ä»¥ä¸‹ã®å†…å®¹ã‚’è²¼ã‚Šä»˜ã‘ã¾ã™ï¼š

```ini
[Unit]
Description=GPU Monitoring API Agent
After=network.target docker.service

[Service]
User=root
WorkingDirectory=/opt/gpu-monitor
ExecStart=uvicorn monitor:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

ä¿å­˜ã—ã¦ã‚¨ãƒ‡ã‚£ã‚¿ã‚’çµ‚äº†ã—ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚’æœ‰åŠ¹åŒ–ãƒ»èµ·å‹•ã—ã¾ã™ã€‚

```bash
sudo systemctl daemon-reload
sudo systemctl enable gpu-monitor
sudo systemctl start gpu-monitor
```

---

### Step 3: ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š (é‡è¦) ğŸ›¡ï¸

`ERR_CONNECTION_RESET` ã‚„æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã™ã‚‹å ´åˆã€ã‚µãƒ¼ãƒãƒ¼ã®ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ãŒãƒãƒ¼ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒãƒ¼ãƒˆã‚’é–‹æ”¾ã—ã¦ãã ã•ã„ã€‚

#### GPUã‚µãƒ¼ãƒãƒ¼å´ (ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ãƒãƒ¼ãƒˆ: 8000)
```bash
# UFW (Ubuntuæ¨™æº–) ã®å ´åˆ
sudo ufw allow 8000/tcp
sudo ufw reload

# Firewalld (CentOS/RHELç³») ã®å ´åˆ
sudo firewall-cmd --add-port=8000/tcp --permanent
sudo firewall-cmd --reload
```

#### ç®¡ç†è€…PCå´ (Reactã‚¢ãƒ—ãƒªç”¨ãƒãƒ¼ãƒˆ: 3000)
â€» `npm start` ã§ã‚¢ãƒ—ãƒªã‚’ãƒ›ã‚¹ãƒˆã—ã¦ã„ã‚‹PCã«å¯¾ã—ã¦ã€ä»–ã®PCã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å ´åˆã®ã¿å¿…è¦ã§ã™ã€‚

```bash
sudo ufw allow 3000/tcp
sudo ufw reload
```

---

### Step 4: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ãƒ—ãƒªã®èµ·å‹• (ç®¡ç†è€…PC)

å†ã³ç®¡ç†è€…PCï¼ˆãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸPCï¼‰ã«æˆ»ã‚Šã¾ã™ã€‚

#### 1. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
npm install
```

#### 2. ã‚¢ãƒ—ãƒªã®èµ·å‹•
é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚

```bash
npm start
```

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:3000`ï¼ˆã¾ãŸã¯è¡¨ç¤ºã•ã‚ŒãŸURLï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™ã€‚
å³ä¸Šã®ã€ŒAdd Serverã€ãƒœã‚¿ãƒ³ã‹ã‚‰ã€Step 2ã§è¨­å®šã—ãŸã‚µãƒ¼ãƒãƒ¼ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆä¾‹: `192.168.1.50`ï¼‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

---

## â“ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q. IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¿½åŠ ã—ã¦ã‚‚ "Connection lost" ã«ãªã‚‹
1. **IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®ç¢ºèª:** ç™»éŒ²ã—ãŸIPãŒã€ã‚¢ãƒ—ãƒªã‚’é–‹ã„ã¦ã„ã‚‹PCã‹ã‚‰åˆ°é”å¯èƒ½ã‹ (`ping 192.168.1.XX`) ç¢ºèªã—ã¦ãã ã•ã„ã€‚
2. **ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«:** Step 3ã®ãƒãƒ¼ãƒˆé–‹æ”¾ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
3. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•ç¢ºèª:** GPUã‚µãƒ¼ãƒãƒ¼ã§ `curl http://localhost:8000` ã‚’å®Ÿè¡Œã—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¿”ã‚‹ã‹ã€ã¾ãŸã¯ `sudo systemctl status gpu-monitor` ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
4. **Mixed Content:** GitHub Pages (HTTPS) ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€HTTPã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯æ¥ç¶šã§ãã¾ã›ã‚“ã€‚è©³ç´°ã¯ `docs/GITHUB_PAGES.md` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### Q. Dockerã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¡¨ç¤ºã•ã‚Œãªã„
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ `docker` ã‚°ãƒ«ãƒ¼ãƒ—ã«æ‰€å±ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
`monitor.py` ã‚’ `root` æ¨©é™ã§å®Ÿè¡Œã™ã‚‹ã‹ã€å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’dockerã‚°ãƒ«ãƒ¼ãƒ—ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
```bash
sudo usermod -aG docker $USER
# å†ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦
```
